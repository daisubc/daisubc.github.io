---
layout: publication
title: "A Meta-Reinforcement Learning Approach to Process Control"
type: "conference"
order: 153
year: 2021
authors: "Daniel G. McClement, Nathan P. Lawrence, Philip D. Loewen, Michael G. Forbes, Johan U. Backstrom and R. Bhushan Gopaluni"
journal: "In Proceedings of the 16th IFAC International Symposium on Advanced Control of Chemical Processes (ADCHEM 2021)"
notes: "Keynote Presentation"
external_url: "https://www.sciencedirect.com/science/article/pii/S2405896321010958"
slides: "2021IFAC_Daniel_Slides.pptx"
pdf: "2021C2_McClement_ADCHEM.pdf"
video: "https://vimeo.com/573573806"
thumbnail: "mcclement_adchem_2021.png"
arxiv: "https://arxiv.org/abs/2103.14060"
description: "Meta-learning is a branch of machine learning which aims to quickly adapt models, such as neural networks, to perform new tasks by learning an underlying structure across related tasks. In essence, models are being trained to learn new tasks effectively rather than master a single task. Meta-learning is appealing for process control applications because the perturbations to a process required to train an AI controller can be costly and unsafe. Additionally, the dynamics and control objectives are similar across many different processes, so it is feasible to create a generalizable controller through meta-learning capable of quickly adapting to different systems. In this work, we construct a deep reinforcement learning (DRL) based controller and meta-train the controller using a latent context variable through a separate embedding neural network. We test our meta-algorithm on its ability to adapt to new process dynamics as well as different control objectives on the same process. In both cases, our meta-learning algorithm adapts very quickly to new tasks, outperforming a regular DRL controller trained from scratch. Meta-learning appears to be a promising approach for constructing more intelligent and sampleefficient controllers."
---
